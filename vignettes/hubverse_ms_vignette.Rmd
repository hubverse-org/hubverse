---
title: "Supplemental Code Demo"
subtitle: "Accessing Data from the US Flusight Hubverse Project"
author: 
- Consortium of Infectious Disease Modeling Hubs
- Melissa Kerr
- Rebecca Borchering
- Alvaro Castro Rivadeneira
- Lucie Contamin
- Sebastian Funk
- Harry Hochheiser
- Emily Howerton
- Anna Krystalli
- Li Shandross
- Nicholas G Reich
date: "`r Sys.Date()`"
output: 
  pdf_document:
    citation_package: natbib
bibliography: references.bib
---


```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE
)
```

# Software configuration
The following demonstration shows how to access and analyze data from a real hub using `r R.version$string` and several of the hubverse R packages.[@the_consortium_of_infectious_disease_modeling_hubs_hubverse_2025] The following packages are on CRAN and may be installed using the standard `install.packages()` function: `hubEnsembles`, `aws.s3`, `arrow`, `ggplot2` and `dplyr`.

The hubverse packages `hubData`, `hubVis`, and `hubEvals` must be installed through the R-universe package repository using the commands below.
```{r install, eval=FALSE}
install.packages(pkgs = c("hubData", "hubVis", "hubEvals"),
                 repos = c("https://hubverse-org.r-universe.dev",
                           "https://cloud.r-project.org"))
```

Once the required packages are installed, load them into your R session. (Session information including package versions are included at the end of this vignette.)

```{r libraries, message=FALSE}
library(hubData)
library(hubEnsembles)
library(hubVis)
library(hubEvals)
```

```{r, echo=FALSE}
ggplot2::theme_set(ggplot2::theme_bw())
```


# Load forecast data
CDC's FluSight Forecast Hub exists as a [GitHub repository](https://github.com/cdcepi/FluSight-forecast-hub).[@noauthor_cdcepiflusight-forecast-hub_2025] Using hubverse tools, it also has been mirrored to the cloud, so a copy of the data lives at a publicly-accessible AWS S3 bucket. This means that instead of needing to download a local copy of the repository, the data for this project can be directly accessed from the cloud using `hubData` tools.

We start by initializing a connection to the hub in the cloud. Below, we print out metadata about the resulting connection. This is by default not printed, but examining it shows how the hub configuration is passed to the various utilities.
```{r}
(hub_con <- hubData::s3_bucket("cdcepi-flusight-forecast-hub/") |>
   hubData::connect_hub(skip_checks = TRUE))
```

We then collect a subset of model output that we will interact with further in this demonstration. Specifically, we will extract zero through three week-ahead quantile predictions of weekly incident flu hospitalizations made for the state of Texas on three dates in late 2023 and early 2024. For simplicity, we will restrict our query to predictions made for five arbitrarily chosen models, although predictions for over 30 models are available on each of these dates.

```{r}
models <- c("FluSight-baseline",
            "CMU-TimeSeries",
            "UMass-flusion",
            "cfa-flumech",
            "UGA_flucast-INFLAenza")
reference_dates <- c("2023-12-16", "2024-01-13", "2024-02-10")

flusight_data <- hub_con |>
  dplyr::filter(target == "wk inc flu hosp",
                reference_date %in% reference_dates,
                model_id %in% models,
                output_type == "quantile",
                location == "48", ## FIPS code for Texas
                horizon > -1) |>
  hubData::collect_hub()
```


```{r, echo=FALSE}
knitr::kable(flusight_data[116:120,
                           c("model_id", "reference_date", "location",
                             "output_type", "output_type_id", "value")],
             digits = 2,
             caption = "Five rows of the `flusight_data` object collected above.
             The \"target\", \"horizon\", and \"target_end_date\" columns have
             been excluded for readability. The \"output_type_id\" and \"value\"
             columns show the different predicted quantiles for the number of
             hospital admissions due to influenza made by the CMU-TimeSeries
             model for location 48 (Texas). The predictions were made during the
             week of December 16, 2023 (reference date) and are making a
             prediction for the horizon of 1 week ahead, for the week ending
             December 23.")
```


# Loading target data

We can use the `aws.s3` package to read the contents of the most up-to-date target data file stored in the cloud.

```{r, message=FALSE}
target_data <-
  aws.s3::s3read_using(
    readr::read_csv,
    object = "s3://cdcepi-flusight-forecast-hub/target-data/target-hospital-admissions.csv" #nolint
  ) |>
  dplyr::mutate(target = "wk inc flu hosp") |>
  dplyr::select(date, target, location, value) |> # keep only required columns
  dplyr::filter(location == "48",
                date >= as.Date("2023-09-23"), date <= as.Date("2024-05-01")) |>
  dplyr::rename(observation = value) |>
  dplyr::arrange(date)
```

```{r, echo=FALSE}
knitr::kable(target_data[1:5, ], digits = 2,
             caption = "Five rows of the `target_data` object read in above.
             The observation column shows the number of hospital admissions
             due to influenza reported in Texas (location 48) on the week
             ending on each date.")
```

\clearpage 

## Visualize forecasts

We can use the hubVis package to create a single graphic that overlays the forecasts from the five models and three forecast dates with the observed data.

```{r, fig.cap = "Forecasts of hospital admissions in Texas due to influenza in the 2023-2024 respiratory virus season. Predictions from five models are shown along with observed data (line with dots for specific observations). Each model is shown in a different color, with the 80% prediction intervals shown as a shaded region.", fig.width = 9, fig.height = 6}  
flusight_data |>
  hubVis::plot_step_ahead_model_output(
    target_data,
    x_col_name = "target_end_date",
    use_median_as_point = TRUE,
    group = "reference_date",
    interactive = FALSE,
    fill_transparency = .1,
    intervals = 0.8
  ) +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::ylab("hospital admissions due to influenza")
```

\clearpage 

# Build ensemble and visualize

Using the model output data collected above, we can pass these data to the `hubEnsembles::simple_ensemble()` function to build an ensemble that takes the mean of predicted values from each model at each quantile level. This new forecast output is then added to the existing forecasts and visualized all together. The hubEnsembles package supports a range of aggregation approaches including a linear opinion pool (probability density averaging) or using the mean or median of quantiles.[@shandross_multi-model_2025] Model weights can be specified for the various approaches, allowing for some models to influence the output more strongly.

```{r, fig.cap = "Forecasts of hospital admissions in Texas due to influenza in the 2023-2024 respiratory virus season. Predictions from five submitted models and an ensemble are shown along with observed data. The observed data are shown as a line with dots for specific weekly observations. Each individual model is shown in orange and the mean ensemble is shown in black, with the 80% prediction intervals shown as shaded regions."}
ensemble_forecast <- hubEnsembles::simple_ensemble(flusight_data)

all_forecasts <- flusight_data |>
  dplyr::bind_rows(ensemble_forecast)

all_forecasts |>
  hubVis::plot_step_ahead_model_output(target_data,
                                       x_col_name = "target_end_date",
                                       use_median_as_point = TRUE,
                                       group = "reference_date",
                                       interactive = FALSE,
                                       fill_transparency = .2,
                                       intervals = 0.90,
                                       one_color = "darkgray",
                                       ens_name = "hub-ensemble",
                                       ens_color = "orange",
                                       pal_color = NULL) +
  ggplot2::theme(legend.position = "bottom") +
  ggplot2::ylab("hospital admissions due to influenza")
```

\clearpage

# Evaluate forecasts

The package hubEvals can be used to evaluate probabilistic predictions against observed data. The hubEvals package creates an interface for hubverse-style model output and target data to the scoringutils package, which is an engine for computing a number of common scores for probabilistic predictions.[@bosse-scoringutils-2024] 

The code below starts by making oracle output data, which is a dataset formatted like hubverse-style model output data but with a point prediction representing the eventual observation, as if observed by an oracle model. The FluSight hub stores target data in a time-series format but not in an oracle output format. The oracle output data format is convenient to use for scoring, as it can be joined with model output data and then the observation and the prediction reside in a single row of stored data. In this example, we compute and show results for the weighted interval score (WIS) with its associated decomposition into overprediction, underprediction, and dispersion penalties, the 50% and 90% prediction interval coverage rates, and the absolute error computed on the median prediction.[@bracher_evaluating_2021]

```{r, fig.cap = "Average weighted interval score (WIS) computed by model (y-axis). The total length of each bar is the average WIS across all predictions made. WIS can be decomposed into penalties for overprediction, underprediction and dispersion, the contributions of which are shown by the segments of the bar. The UMass-flusion model has the lowest (best) average WIS, and it received a greater penalty for underprediction relative to the penalty for overprediction."}
## make oracle output
oracle_output <- target_data |>
  dplyr::select(date, location, observation) |>
  dplyr::rename(target_end_date = date,
                oracle_value = observation) |>
  tidyr::crossing(horizon = 0:3) |>
  dplyr::mutate(reference_date = as.Date(target_end_date) - horizon * 7L) |>
  dplyr::filter(reference_date %in% reference_dates)

scores <- hubEvals::score_model_out(all_forecasts,
                                    oracle_output,
                                    baseline = "FluSight-baseline") |>
  dplyr::arrange(wis)

scoringutils::plot_wis(scores, x = "model_id")
```


```{r, echo=FALSE}
knitr::kable(scores[, c(1:2, 7:9)], digits = 2,
             caption = "A print-out of the `scores` object computed above,
             containing the summary metrics for the five component models and
             the ensemble model. Columns including other metrics, including
             bias, underprediction, overprediction and dispersion were omitted
             for space.")
```

\clearpage
# Session information

```{r}
sessionInfo()
```

